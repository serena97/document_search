{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.marco import get_sentences\n",
    "# from model.word2vec import get_model, train_model\n",
    "# from gensim.utils import simple_preprocess\n",
    "\n",
    "# raw_sentences = get_sentences()\n",
    "# tokenized_sentences = [simple_preprocess(sentence) for sentence in raw_sentences]\n",
    "# skipgram_model = get_model(tokenized_sentences)\n",
    "# train_model(skipgram_model, tokenized_sentences)\n",
    "\n",
    "# model_path = \"./artifacts/word2vec-300.bin\"\n",
    "# skipgram_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08166109, -0.05603082,  0.08131558,  0.1453118 , -0.02772139,\n",
       "        0.3336876 ,  0.26576355, -0.20260681,  0.18647544, -0.06265885,\n",
       "       -0.02537769,  0.27152473,  0.18361786, -0.22557825,  0.06676365,\n",
       "       -0.14489435,  0.20553292,  0.03955898,  0.21805419,  0.32962334,\n",
       "        0.03388114,  0.21090184,  0.20374602, -0.11790657, -0.10713933,\n",
       "       -0.17888841,  0.12195691,  0.08326802,  0.08338279,  0.1702925 ,\n",
       "        0.42584544, -0.15946382,  0.00752363,  0.36911058,  0.00319007,\n",
       "        0.09264715, -0.07176673, -0.14241076, -0.04268489, -0.10397603,\n",
       "        0.3095556 ,  0.09982298,  0.12000576, -0.0958479 ,  0.0315978 ,\n",
       "       -0.29556945,  0.1510915 ,  0.21604806,  0.14024083, -0.32941374,\n",
       "        0.27504742,  0.15409113,  0.0196512 , -0.1924288 , -0.13030423,\n",
       "        0.28063247,  0.0216731 ,  0.01504864,  0.09892328, -0.09026737,\n",
       "       -0.07826483,  0.08209728,  0.00135547, -0.12017546,  0.224457  ,\n",
       "       -0.2233952 ,  0.20976582, -0.02407778,  0.17635925, -0.21205437,\n",
       "       -0.20269059, -0.34664237,  0.1120103 , -0.01134748, -0.26983732,\n",
       "       -0.06351115,  0.00639086,  0.01653231, -0.30118635, -0.18481167,\n",
       "        0.01016396, -0.2612085 ,  0.20080468, -0.2865284 ,  0.31910387,\n",
       "       -0.02621699,  0.11730092, -0.00171843,  0.0603199 , -0.46296272,\n",
       "       -0.3011974 , -0.17535649,  0.11510366, -0.19788904,  0.14543791,\n",
       "       -0.2165444 , -0.0237995 ,  0.18728098,  0.14261219,  0.35801345,\n",
       "        0.0289009 , -0.17348088,  0.13863593,  0.25453016,  0.0142446 ,\n",
       "       -0.09372912, -0.0614436 ,  0.04119324,  0.06195934,  0.22805206,\n",
       "        0.15288045, -0.04521697, -0.02545284,  0.25815988, -0.18435133,\n",
       "        0.0994409 , -0.04027909, -0.33957872,  0.15270513, -0.13419022,\n",
       "        0.21689154,  0.13394181,  0.08122249, -0.15684637, -0.5502501 ,\n",
       "        0.19885015,  0.00670672, -0.23747313,  0.02113836, -0.11731804,\n",
       "       -0.05761037, -0.15730692, -0.04095507, -0.05831743,  0.07682261,\n",
       "       -0.11957532, -0.22121082, -0.33204544, -0.0731948 , -0.36075723,\n",
       "        0.3457575 , -0.27701756, -0.03342834,  0.15543318,  0.32302794,\n",
       "        0.33372155, -0.13742812,  0.03362711,  0.10144056,  0.06350777,\n",
       "       -0.24920419,  0.15035467, -0.07955882,  0.00653558,  0.1684746 ,\n",
       "        0.46073478, -0.37230724, -0.47737804, -0.03416205,  0.06983148,\n",
       "       -0.11218081, -0.26085368,  0.00409142,  0.02896973,  0.2839493 ,\n",
       "        0.02061277,  0.24958542,  0.1085683 , -0.17433795,  0.47907236,\n",
       "       -0.01353128,  0.18986408,  0.2012165 ,  0.06458036, -0.17617285,\n",
       "        0.2877804 , -0.361407  ,  0.08317471, -0.26325002, -0.03455486,\n",
       "       -0.01549144,  0.2636886 , -0.08120844, -0.3780883 , -0.23095022,\n",
       "        0.08388415,  0.01614934, -0.13979809, -0.2671702 , -0.19130133,\n",
       "       -0.31033975, -0.11530315, -0.36522108,  0.00898996,  0.06286199,\n",
       "        0.21437562, -0.02457768, -0.02508277, -0.30442494,  0.29343322,\n",
       "       -0.04051777, -0.04536847,  0.03147078, -0.11058688, -0.12784575,\n",
       "        0.3405573 ,  0.19849828,  0.15034094,  0.1392878 ,  0.10277504,\n",
       "        0.01243323, -0.1702786 ,  0.30424556,  0.11050113,  0.03167301,\n",
       "        0.0925282 , -0.09827267,  0.13529249,  0.18732819, -0.20175084,\n",
       "       -0.01723487, -0.24339819,  0.2476172 ,  0.09948768,  0.10175581,\n",
       "       -0.32905102, -0.15850067, -0.1302452 ,  0.11615583,  0.14732482,\n",
       "        0.23910607,  0.02004572, -0.08359036, -0.3279946 ,  0.2847214 ,\n",
       "        0.12959862, -0.03992394, -0.40531763, -0.36975437,  0.10998885,\n",
       "       -0.25256366,  0.35222685,  0.1310796 , -0.17981492,  0.03445696,\n",
       "        0.10784263,  0.21457233,  0.00281171,  0.09659303,  0.31171525,\n",
       "       -0.36752388,  0.17239916,  0.1429536 ,  0.06172667, -0.02569523,\n",
       "       -0.13586009,  0.27978468,  0.05923641, -0.13546202, -0.24113823,\n",
       "        0.36671215, -0.05251275,  0.30366427,  0.03448543,  0.02719153,\n",
       "       -0.18542129,  0.42159754, -0.10096669, -0.41682902,  0.03220028,\n",
       "        0.07831725,  0.18270482, -0.0731294 ,  0.24887104,  0.267636  ,\n",
       "       -0.22580346, -0.04360627,  0.10893843,  0.01487952,  0.04521329,\n",
       "        0.06420681, -0.35157794, -0.18730853,  0.12463242,  0.12062994,\n",
       "        0.11437279, -0.1831197 ,  0.07736847, -0.01039842, -0.16114117,\n",
       "       -0.22693217, -0.37547243, -0.00564416, -0.08752664, -0.1924926 ,\n",
       "        0.202733  ,  0.05556782, -0.46606895,  0.01069038, -0.1345109 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_path = \"./artifacts/word2vec-300.bin\"\n",
    "model = Word2Vec.load(model_path)\n",
    "model.wv['what']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Unzip the batch into lists of queries, relevant_docs, and irrelevant_docs\n",
    "    query_emb_list, relevant_doc_emb_list, irrelevant_doc_emb_list = zip(*batch)\n",
    "    \n",
    "    # Pad sequences for relevant and irrelevant documents\n",
    "    # This assumes each document is already a tensor of embeddings; adjust if the structure is different\n",
    "    padded_relevant = pad_sequence([pad_sequence(docs, batch_first=True) for docs in relevant_doc_emb_list], batch_first=True)\n",
    "    padded_irrelevant = pad_sequence([pad_sequence(docs, batch_first=True) for docs in irrelevant_doc_emb_list], batch_first=True)\n",
    "    \n",
    "    # Pad the sequences of query embeddings\n",
    "    query_emb_tensor = pad_sequence(query_emb_list, batch_first=True)\n",
    "\n",
    "    return query_emb_tensor, padded_relevant, padded_irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.twotowermodel import DocumentTower, QueryTower\n",
    "from data.dataset import QueryDocumentDataset\n",
    "from data.marco import get_training_dataset\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loss_function import triplet_loss_function\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model and optimizer\n",
    "document_model = DocumentTower(embedding_dim=300, hidden_dim=128).to(device)\n",
    "query_model = QueryTower(embedding_dim=300, hidden_dim=128).to(device)\n",
    "\n",
    "optimizer = Adam(list(document_model.parameters()) + list(query_model.parameters()), lr=0.001)\n",
    "\n",
    "dataset_instance = QueryDocumentDataset(data=get_training_dataset(), embedding_model=model)\n",
    "dataloader = DataLoader(dataset_instance, batch_size=32, shuffle=False, collate_fn=custom_collate)  # You can adjust batch_size as needed\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for query_emb, relevant_doc_emb, irrelevant_doc_emb in dataloader:\n",
    "    # Convert the tokens to embeddings\n",
    "    # Forward pass to get encodings for two tower\n",
    "\n",
    "    query_emb = query_emb.to(device)\n",
    "    relevant_doc_emb = relevant_doc_emb.to(device)\n",
    "    irrelevant_doc_emb = irrelevant_doc_emb.to(device)\n",
    "\n",
    "    relevant_doc_encoding, irrelevant_doc_encoding = document_model(relevant_doc_emb, irrelevant_doc_emb)\n",
    "    query_encoding = query_model(query_emb)\n",
    "\n",
    "    # Compute triplet loss\n",
    "    loss = triplet_loss_function(query_encoding, relevant_doc_encoding, irrelevant_doc_encoding, margin=0.3)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    if counter % 1000 == 0:\n",
    "        print(f\"Triplet loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
